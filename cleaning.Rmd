---
title: "baseline_data_clean"
author: "Madeline Berger"
date: "11/8/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(sf)
library(stringr)

lat_lon <- read.csv("lag_lng_allbaseline.csv")

head(lat_lon$latitude[1])

x = lat_lon$latitude[1]

#create a unique identifier for each group of vertices by merging the plot id column with the farmer id to create a new id

lat_lon_id <- lat_lon %>%
  mutate(unique_id=paste(substr(plot_id, 2, 2), resp_id))
  

lat_lon_id$unique_id <- gsub(" ", "", lat_lon_id$unique_id, fixed = TRUE)
  #unite("unique_id", plot_id, a_hhid, remove = FALSE)




```

Data Cleaning
```{r}
#find any values with Na

summary(lat_lon_id)

check_na <- lat_lon_id %>% 
  filter(is.na(a_hhid) | is.na(longitude))

#remove all NAs
clean <- lat_lon[complete.cases(lat_lon), ]

clean_id <-lat_lon_id[complete.cases(lat_lon_id), ]
```



Creating vectors
##-unique id, resp Id

```{r}
#unique id 

id_vec <- unique(clean_id$unique_id) #make a list of all the values in unique_id column, can this be numeric?

#try with resp id

id_vec_resp <- unique(clean$resp_id)

#try with a_hhid

id_vec_ah <-unique(clean$a_hhid)


#old - from before it was clean, just to compare which are missing

id_vec_old <- unique(lat_lon_id$unique_id)

id_vec_resp_old <- unique(lat_lon$resp_id)

```



Data Exploration
###1 How many loops are we dealing with?
###2 What are the first and last values?


```{r}
#aparently, resp_id is unique to polygons

#1.How many unique resp_ids?
length(id_vec_resp)

head(id_vec_resp)

tail(id_vec_resp,1)

#2. How many unique_ids?

length(id_vec)

#4. How many a_hhid

length(id_vec_ah)

#4.Compared to old?

length(id_vec_old)

```



Create subsets for testing
```{r}
#with unique Id
#for testing
df_short <- lat_lon_id %>% 
   filter(unique_id == "110010033" | unique_id == "110010039" | unique_id == "110010075") 

#make a shorter list for the test set
id_vec_test <- unique(df_short$unique_id)


#with resp id 
df_resp <- lat_lon_id %>% 
    filter(resp_id == 101600981) %>% 
    as.matrix
```


Filtered sets post-error
###Removed: 1110600681, 1122201051, 1220301321, 1118200131
```{r}
#second
clean_id_2 <- clean_id %>% 
  filter(unique_id != 1110600681)

id_vec_2 <- unique(clean_id_2$unique_id)

#third

clean_id_3 <- clean_id_2 %>% 
  filter(unique_id != 1122201051)

id_vec_3 <- unique(clean_id_3$unique_id)

#fourth

clean_id_35 <- clean_id_3 %>% 
  filter(unique_id != 1220301371)

clean_id_4 <- clean_id_35 %>% 
  filter(unique_id != 1118200131)

id_vec_4 <- unique(clean_id_4$unique_id)

```





Code to add another point for closure - if needed
```{r}
#making matrices and testing for closure

 id = id_vec[i]
  
df <- lat_lon_id %>% 
    filter(unique_id == id) %>% 
    select(longitude, latitude) %>% 
    as.matrix

line_sf <- st_linestring(df)

plot(line_sf)

#check whether the first and last rows are the same point: 

df[1, ] == df[nrow(df), ]

#bind the matrix with its own first row to close it

df_closed <- rbind(df, df[1, ])

#check again if the first and last rows are closed

df_closed[1, ] == df_closed[nrow(df_closed), ]

line_sf_closed <- st_linestring(df_closed)

plot(line_sf_closed)


```

Loop to make polygons
```{r}
for(i in seq_along(unique(clean_id_4$unique_id))){
  #filter the df 
  print(i)
  
  id = id_vec_4[i]
  
  df <- clean_id_4 %>% 
    filter(unique_id == id) %>% 
    select(longitude,latitude)
    as.matrix
    
  print(i)
  #get the coodrinates
  #create the polygon, and add attributes
  poly <- st_sf(data.frame(unique_id = id, 
                           st_sfc(st_polygon(list(as.matrix(df))),crs = 4326)))
  
 print(i)
  
 if(i == 1) {
   poly_sf <- poly
 } else {
   poly_sf <- rbind(poly_sf, poly)
 }
 
print(i)
  
}

#another idea to try: 



```


Bind poly_id, farmer id, and family id to poly_sf 

```{r}

#create table of IDs minus the lat lon data

info <- clean_id_4[-c(1,4:5)]


#merge  - tried three ways

poly_complete_merge <- merge(info, poly_sf, by = "unique_id")

poly_complete_join <- merge(x = info, y = poly_sf, by = "unique_id")

join <- left_join(info %>% group_by(unique_id) %>% mutate(id = row_number()), poly_sf %>% group_by(unique_id) %>% mutate(id = row_number()), by= c("unique_id", "id"))

#USE THIS ONE - removed the duplicates from the one above


clean_done <- poly_complete_merge[!duplicated(poly_complete$unique_id), ]

```



Writing out shapefiles and csv
```{r}
st_write(poly_sf, "test_noinfo.shp")

st_write(clean_done, "test_all.shp")

#better if you could add a path, worry about this later


write_csv(clean_id, "H:/punjab_project/punjab_project/ids_2.csv", col_names = TRUE)

write_csv(clean_id_3, "H:/punjab_project/punjab_project/ids_3.csv", col_names = TRUE)
```



Issue remaining - not all the first and last coordinates are the same! They have to be in order

##################################

New thing: try to write a loop that tests resp_id

```{r}
#testing grouping
group_by_resp <- lat_lon %>% 


#new loop 

for(i in seq_along(unique(lat_lon$resp_id))){
  #filter the df 
  id = id_vec_resp[i]
  
  df <- lat_lon %>% 
    filter(resp_id == id) %>% 
    select(resp_id,latitude, longitude)
   
    
  if(df[1,2] != df[nrow(df),2]){  
    print()
  }
}

#poly <- st_sf(data.frame(resp_id = id, st_sfc(st_polygon(list(as.matrix(df))),crs = 4326)))

###############################
```


Why is the second one failing?
```{r}

#using resp id

df_test_resp <- lat_lon %>% 
  filter(resp_id == 100100331) %>% 
  select(latitude,longitude)

df_test_resp
  
poly <- st_sf(data.frame(resp_id = 100100331, st_sfc(st_polygon(list(as.matrix(df_test_resp))),crs = 4326)))


#using unique id

df_test_uniq <- clean_id_3%>% 
  filter(unique_id == 1122201051) %>% 
  select(latitude,longitude)


poly_uniq <- st_sf(data.frame(resp_id = 100100331, st_sfc(st_polygon(list(as.matrix(df_test_uniq))),crs = 4326)))

df_test_uniq

#so this works but the one above does not
```

Overall - NONE of these IDs are unique to the polygon!!


######################################

Notes from kelsey
a_hhid = farmer / household id 
missing for 25 observations

resp_id = 
is never missing 

some a_hhid have more than one 

one missing logtude 

split this id so that you can have a farmer plot panel

when you get a dataset at the plot level 

Priority be: shapefile available in whatever form before you go offline 

Then start working more with the shapefile to merge in information like "was that plot burned"

